{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "main_folder_path = \"5-51 data\"\n",
    "\n",
    "\n",
    "def check_filename(file_name):\n",
    "    file_name_without_extension = os.path.splitext(file_name)[0].lower()\n",
    "    cleaned_name = re.sub(r'[0-9\\.,-]', '', file_name_without_extension)\n",
    "    words = re.findall(r'\\b\\w+\\b', cleaned_name)\n",
    "\n",
    "    for word in words:\n",
    "        if word not in [\"pick\", \"represent\",\"pickrepresent\"]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "for folder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, folder_name)\n",
    "\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(f\"check folder: {folder_name}\")\n",
    "\n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "\n",
    "            if check_filename(file_name):\n",
    "                print(f\"bad file: {file_name} in folder {folder_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_files_with_keyword(src_folder, dst_folder, keyword):\n",
    "\n",
    "    for subdir, dirs, files in os.walk(src_folder):\n",
    "        for file in files:\n",
    "\n",
    "            if keyword in file:\n",
    "\n",
    "                src_file_path = os.path.join(subdir, file)\n",
    "                relative_path = os.path.relpath(subdir, src_folder)\n",
    "                dst_file_path = os.path.join(dst_folder, relative_path, file)\n",
    "\n",
    "\n",
    "                os.makedirs(os.path.dirname(dst_file_path), exist_ok=True)\n",
    "\n",
    "                shutil.copy(src_file_path, dst_file_path)\n",
    "\n",
    "src_folder = '5-51 data' \n",
    "dst_folder = '5-51 data_sort'  \n",
    "keyword = 'pick'  \n",
    "\n",
    "copy_files_with_keyword(src_folder, dst_folder, keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the main folder containing subfolders\n",
    "main_folder_path = \"5-51 data_sort\"\n",
    "\n",
    "# Read the CSV file containing the sample information\n",
    "sample_data = pd.read_csv(\"2022-7-21.csv\")\n",
    "\n",
    "# Create a DataFrame to store the final result\n",
    "final_data = pd.DataFrame()\n",
    "\n",
    "# Iterate through all subfolders in the main folder\n",
    "for folder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, folder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(folder_name)\n",
    "        \n",
    "        # Iterate through the 5 log files in each subfolder\n",
    "        for file_number in range(1, 6):\n",
    "            # Find the file that starts with the specific file number\n",
    "            file_list = [f for f in os.listdir(subfolder_path) if f.startswith(f\"{file_number}-\")]\n",
    "            \n",
    "            if file_list:  # Check if the file list is not empty\n",
    "                log_file_name = file_list[0]\n",
    "                log_file_path = os.path.join(subfolder_path, log_file_name)\n",
    "\n",
    "                # Remove the file extension before splitting\n",
    "                log_file_name_without_extension = os.path.splitext(log_file_name)[0]\n",
    "\n",
    "                # Extract the cross-sectional area and stretch length from the file name\n",
    "                _, cross_section_area, stretch_length, *_ = log_file_name_without_extension.split('-')\n",
    "                cross_section_area = float(cross_section_area)\n",
    "                stretch_length = float(stretch_length)\n",
    "                \n",
    "                # Read the log file\n",
    "                log_data = pd.read_csv(log_file_path, skiprows=5, sep=\"\\t\")\n",
    "                \n",
    "                # Calculate stress and strain\n",
    "                log_data['Stress (MPa)'] = log_data['Load'] / cross_section_area\n",
    "                log_data['Strain (%)'] = (log_data['Travel'] / stretch_length) * 100\n",
    "                \n",
    "                # Extract the sample information from the CSV file\n",
    "                sample_info = sample_data[sample_data['sample'] == int(folder_name)].iloc[0]\n",
    "                \n",
    "                # Combine the sample information with the stress and strain data\n",
    "                combined_data = pd.concat([pd.Series(sample_info)] * len(log_data), axis=1).T\n",
    "                combined_data[['Stress (MPa)', 'Strain (%)']] = log_data[['Stress (MPa)', 'Strain (%)']]\n",
    "                \n",
    "                # Append to the final DataFrame\n",
    "                final_data = final_data.append(combined_data, ignore_index=True)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "#final_data.to_csv(\"final_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the main folder containing subfolders\n",
    "main_folder_path = \"5-51 data_sort\"\n",
    "\n",
    "# Create a directory to store the processed CSV files\n",
    "output_folder_path = \"processed_data_onlypicked\"\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Iterate through all subfolders in the main folder\n",
    "for folder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, folder_name)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(f\"Processing folder: {folder_name}\")\n",
    "\n",
    "        # Iterate through the 5 log files in each subfolder\n",
    "        for file_number in range(1, 10):\n",
    "            file_list = [f for f in os.listdir(subfolder_path) if f.startswith(f\"{file_number}-\")]\n",
    "            \n",
    "            if file_list:  # Check if the file list is not empty\n",
    "                log_file_name = file_list[0]\n",
    "                log_file_path = os.path.join(subfolder_path, log_file_name)\n",
    "                print(f\"Processing file: {log_file_name}\")  # Print the file being processed\n",
    "\n",
    "                # Remove the file extension before splitting\n",
    "                log_file_name_without_extension = os.path.splitext(log_file_name)[0]\n",
    "\n",
    "                # Extract the cross-sectional area and stretch length from the file name\n",
    "                \n",
    "                _, cross_section_area, stretch_length, *_ = log_file_name_without_extension.split('-')\n",
    "                cross_section_area = float(cross_section_area)\n",
    "                stretch_length = float(stretch_length)\n",
    "\n",
    "                # Read the log file\n",
    "                log_data = pd.read_csv(log_file_path, skiprows=5, sep=\"\\t\")\n",
    "\n",
    "                # Calculate stress and strain\n",
    "                log_data['Stress (MPa)'] = log_data['Load'] / cross_section_area\n",
    "                log_data['Strain (%)'] = (log_data['Travel'] / stretch_length) * 100\n",
    "\n",
    "                # Save the stress and strain data to a CSV file with a new name\n",
    "                output_file_name = f\"{folder_name}_{file_number}.csv\"\n",
    "                output_file_path = os.path.join(output_folder_path, output_file_name)\n",
    "                log_data[['Stress (MPa)', 'Strain (%)']].to_csv(output_file_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to the folder containing processed CSV files\n",
    "processed_folder_path = \"processed_data_onlypicked\"\n",
    "\n",
    "# Iterate through all CSV files in the processed folder\n",
    "for file_name in os.listdir(processed_folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(processed_folder_path, file_name)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Remove rows where both Stress and Strain are 0\n",
    "        data = data[(data['Stress (MPa)'] != 0) | (data['Strain (%)'] != 0)]\n",
    "\n",
    "        # Plotting the stress-strain curve\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(data['Strain (%)'], data['Stress (MPa)'], label=\"Stress-Strain Curve\")\n",
    "        plt.title(f\"Stress-Strain Curve for {file_name.split('.')[0]}\")\n",
    "        plt.xlabel(\"Strain (%)\")\n",
    "        plt.ylabel(\"Stress (MPa)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Save the plot as an image\n",
    "        image_file_name = file_name.split('.')[0] + '.png'\n",
    "        image_file_path = os.path.join(processed_folder_path, image_file_name)\n",
    "        plt.savefig(image_file_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Save the cleaned CSV file\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Cleaning and plotting complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path to the folder containing processed CSV files\n",
    "processed_folder_path = \"processed_data_onlypicked\"\n",
    "\n",
    "# Path to the folder where the final CSV files will be saved\n",
    "final_folder_path = \"final_data_onlypicked\"\n",
    "os.makedirs(final_folder_path, exist_ok=True) # Ensure the folder exists\n",
    "\n",
    "# Number of interpolation points (excluding the last point)\n",
    "num_interpolation_points = 49\n",
    "\n",
    "# Iterate through all CSV files in the processed folder\n",
    "for file_name in os.listdir(processed_folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(processed_folder_path, file_name)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Calculate the unit length between adjacent points in the original data (excluding the last point)\n",
    "        unit_length = np.mean(np.diff(data['Strain (%)'].iloc[:-1]))\n",
    "\n",
    "        # Interpolate the stress-strain curve to have 19 points (excluding the last point)\n",
    "        strain_interpolated = np.linspace(data['Strain (%)'].iloc[0], data['Strain (%)'].iloc[-2], num_interpolation_points)\n",
    "        stress_interpolated = np.interp(strain_interpolated, data['Strain (%)'].iloc[:-1], data['Stress (MPa)'].iloc[:-1])\n",
    "\n",
    "        # Create the final data with 20 points, including the last point with 0 stress, using the calculated unit length\n",
    "        final_strain = np.append(strain_interpolated, strain_interpolated[-1] + unit_length) \n",
    "        final_stress = np.append(stress_interpolated, 0)\n",
    "\n",
    "        # Create a DataFrame with the final data\n",
    "        final_data = pd.DataFrame({\n",
    "            'Strain (%)': final_strain,\n",
    "            'Stress (MPa)': final_stress\n",
    "        })\n",
    "\n",
    "        # Create a new file name and path for the final folder\n",
    "        new_file_name = \"final_\" + file_name\n",
    "        final_file_path = os.path.join(final_folder_path, new_file_name)\n",
    "\n",
    "        # Save the final CSV file\n",
    "        final_data.to_csv(final_file_path, index=False)\n",
    "\n",
    "print(\"Interpolation and data modification complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Path to the folder where the final CSV files are saved\n",
    "final_folder_path = \"final_data_onlypicked\"\n",
    "\n",
    "# Iterate through all CSV files in the final folder\n",
    "for file_name in os.listdir(final_folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(final_folder_path, file_name)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Plotting the stress-strain curve\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(data['Strain (%)'], data['Stress (MPa)'], label=\"Stress-Strain Curve\")\n",
    "        plt.title(f\"Stress-Strain Curve for {file_name.split('.')[0]}\")\n",
    "        plt.xlabel(\"Strain (%)\")\n",
    "        plt.ylabel(\"Stress (MPa)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Save the plot as an image\n",
    "        image_file_name = file_name.split('.')[0] + '.png'\n",
    "        image_file_path = os.path.join(final_folder_path, image_file_name)\n",
    "        plt.savefig(image_file_path)\n",
    "        plt.close()\n",
    "\n",
    "print(\"Plotting and saving complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Read the raw material ratio data\n",
    "ratio_data_path = \"2022-7-21.csv\"\n",
    "ratio_data = pd.read_csv(ratio_data_path)\n",
    "# Select only the required columns\n",
    "ratio_data = ratio_data[['sample', 'R1(HA)', 'R2(IA)', 'R3(NVP)', 'R4(AA)', 'R5(HEAA)', 'R6(IBOA)']]\n",
    "\n",
    "# Path to the folder containing the final CSV files\n",
    "final_folder_path = \"final_data_onlypicked\"\n",
    "\n",
    "# Lists to store the input and output data\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "# Iterate through all CSV files in the final folder\n",
    "for file_name in os.listdir(final_folder_path):\n",
    "    if file_name.startswith('final_') and file_name.endswith('.csv'):\n",
    "        print(file_name)\n",
    "        file_path = os.path.join(final_folder_path, file_name)\n",
    "        \n",
    "        # Read the CSV file for stress-strain curve\n",
    "        stress_strain_curve_data = pd.read_csv(file_path)\n",
    "\n",
    "        # Extract sample number from file name\n",
    "        sample_number = int(file_name.split('_')[1])\n",
    "\n",
    "        # Find the corresponding raw material ratios\n",
    "        R_values = ratio_data[ratio_data['sample'] == sample_number].iloc[0, 1:].values\n",
    "\n",
    "        # Flatten the stress-strain curve\n",
    "        stress_strain_curve = stress_strain_curve_data[['Stress (MPa)', 'Strain (%)']].values.flatten()\n",
    "\n",
    "        # Append to the input and output lists\n",
    "        inputs.append(R_values)\n",
    "        outputs.append(stress_strain_curve)\n",
    "\n",
    "# Convert to numpy arrays and ensure float type\n",
    "X = np.array(inputs, dtype=float)\n",
    "y = np.array(outputs, dtype=float)\n",
    "\n",
    "# Split into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data preparation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
